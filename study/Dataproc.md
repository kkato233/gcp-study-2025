# Dataproc まとめ

## 概要
- 対象: マネージド Apache Spark / Hadoop（YARN/HDFS）/ Hive / Presto(Trino)
- 主用途: データレイクのETL/ELT、バッチ処理、一部ストリーミング、機械学習前処理、オンプレHadoop/Sparkの移行
- 実行形態: クラスタ型（短時間起動・オートスケール）と Serverless Spark の両対応

## 利点
- 起動とスケール: クラスタ起動が高速、オートスケール/プリエンプティブル混在でコスト効率
- 連携性: GCS/BigQuery/Bigtable/Pub/Sub/Spanner などGCPネイティブI/Oが豊富
- 柔軟性: 初期化アクション/カスタムイメージでライブラリ・ドライバ・設定を柔軟に導入
- Serverless Spark: 基盤運用ほぼ不要、ジョブ中心の運用（テンポラリに実行して自動解放）

## 欠点
- 運用考慮: クラスタ型はノード/バージョン/スケーリング/メンテ設計が必要
- オーバーヘッド: 超短時間・ごく小規模処理では起動コストが相対的に大きい
- 厳格要件: 低レイテンシや exactly-once を強く求めるストリーミングは設計難度が上がる

## 価格の利点
- 従量と最適化: 秒課金（VM）＋小額の管理料。プリエンプティブルVMやオートスケールで圧縮可能
- Serverless Spark: 実行中リソースのみ課金でアイドルコストほぼゼロ
- エコシステム効果: GCS/BigQuery等のマネージド基盤活用で運用人件費を削減

## 価格の欠点
- 常時稼働: 24/7の常駐クラスタは費用が積み上がる（必要時起動が前提）
- 周辺費用: BigQuery/Storage/ネットワーク/ログの費用が別途加算
- チューニング依存: ワーカタイプ/シャッフル/キャッシュ設計次第でコストが大きく変動

## 選定の目安
- 向く: 既存Spark/Hadoop資産の移行、PySpark/Scalaのコード資産中心ETL、特殊ライブラリやドライバが必要
- 代替: SQL中心の大規模集計→ BigQuery、バッチ/ストリーム統一＋再処理制御→ Dataflow、軽量バッチ/コンテナ→ Cloud Run Jobs

## コスト最適化 Tips
- クラスタ型: オートスケール/プリエンプティブル混在、スケジュール起動停止、適切なワーカタイプ選定
- Serverless Spark: 入出力の局所性（同リージョンGCS/BigQuery）、ジョブパーティション最適化
- I/O最適化: キャッシュ/ブロードキャストの活用、不要データの早期フィルタ、チェックポイント設計
- 観測性: メトリクス/ログを可視化し、ホットスポットやシャッフル量を継続的に削減
